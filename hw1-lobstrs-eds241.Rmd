---
title: "Assignment 1"
subtitle: "California Spiny Lobster (*Panulirus Interruptus*): Assessing the Impact of Marine Protected Areas (MPAs) at 5 Reef Sites in Santa Barbara County" 
author: "EDS 241 / ESM 244 (**Due: 1/17**)"
date: "1/8/26"
output: 
    html_document:
      theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=TRUE, warning = FALSE, message = FALSE )
```

------------------------------------------------------------------------

![](figures/spiny2.jpg)

------------------------------------------------------------------------

### Assignment Instructions:

-   Working with partners to troubleshoot code and concepts is encouraged! If you work with a partner, please list their name next to yours at the top of your assignment so Annie and I can easily see who collaborated.

-   All written responses must be written independently (**in your own words**).

-   Please follow the question prompts carefully and include only the information each question asks in your submitted responses.

-   Submit both your knitted document and the associated `RMarkdown` or `Quarto` file.

-   Your knitted presentation should meet the quality you'd submit to research colleagues or feel confident sharing publicly. Refer to the rubric for details about presentation standards.

**Assignment submission (YOUR NAME):** Zach Loo

------------------------------------------------------------------------

```{r}

library(tidyverse)
library(here)
library(janitor)
library(estimatr)  
library(performance)
library(jtools)
library(gt)
library(gtsummary)
library(interactions) 
library(ggridges)

```

------------------------------------------------------------------------

#### DATA SOURCE:

> [Reed D. 2019. SBC LTER: Reef: Abundance, size and fishing effort for California Spiny Lobster (Panulirus interruptus), ongoing since 2012. Environmental Data Initiative.](https://doi.org/10.6073/pasta/a593a675d644fdefb736750b291579a0) Data accessed 11/17/2019.

------------------------------------------------------------------------

### **Introduction**

You're about to dive into some deep data collected from five reef sites in Santa Barbara County, all about the abundance of California spiny lobsters! ðŸ¦ž Data was gathered by divers annually from 2012 to 2018 across Naples, Mohawk, Isla Vista, Carpinteria, and Arroyo Quemado reefs.

Why lobsters? Well, this sample provides an opportunity to evaluate the impact of Marine Protected Areas (MPAs) established on January 1, 2012 (Reed, 2019). Of these five reefs, Naples, and Isla Vista are MPAs, while the other three are not protected (non-MPAs). Comparing lobster health between these protected and non-protected areas gives us the chance to study how commercial and recreational fishing might impact these ecosystems.

We will consider the MPA sites the `treatment` group and use regression methods to explore whether protecting these reefs really makes a difference compared to non-MPA sites (our control group). In this assignment, weâ€™ll think deeply about which causal inference assumptions hold up under the research design and identify where they fall short.

Letâ€™s break it down step by step and see what the data reveals! ðŸ“Š

![](figures/map-5reefs.png)

------------------------------------------------------------------------

#### Step 1: Anticipating potential sources of selection bias

**a.** Do the control sites (Arroyo Quemado, Carpenteria, and Mohawk) provide a strong counterfactual for our treatment sites (Naples, Isla Vista)? Write a paragraph making a case for why this comparison is ceteris paribus or whether selection bias is likely (be specific!).

To analyze the causal effect of MPAs on lobster abundance, we need these study sites to be "equal" in every way besides MPA status. This could be done if policymakers flipped a coin to assign protection status at each of these sites, essentially assigning at random. This randomness would ideally make the sites statistically identical on average and we could observe the differences after MPA treatment. To my knowledge, I'm not sure how these sites were assigned to be treated or not but usually in policymaking, assigning treatment as random isn't likely. Instead, if sites that were already degraded were assigned as the treatment, this would be assignment based on an unobservable factor, making selection bias a worry.

------------------------------------------------------------------------

#### Step 2: Read & wrangle data

**a.** Read in the raw data from the "data" folder named `spiny_abundance_sb_18.csv`. Name the data.frame `rawdata`

**b.** Use the function `clean_names()` from the `janitor` package

```{r}
# HINT: check for coding of missing values (`na = "-99999"`)

rawdata <- read_csv(here::here("data", "spiny_abundance_sb_18.csv"), na = c(-99999, "NA")) |> 
    janitor::clean_names()

```

**c.** Create a new `df` named `tidydata`. Using the variable `site` (reef location) create a new variable `reef` as a `factor` and add the following labels in the order listed (i.e., re-order the `levels`):

```         
"Arroyo Quemado", "Carpenteria", "Mohawk", "Isla Vista",  "Naples"
```

```{r}

tidydata <- rawdata |> 
    mutate(reef = case_when(
        site == "IVEE" ~ "Isla Vista",
        site == "NAPL" ~ "Naples",
        site == "AQUE" ~ "Arroyo Quemado",
        site == "CARP" ~ "Carpenteria",
        site == "MOHK" ~ "Mohawk"
    )) |> 
    arrange(factor(reef, levels = c("Arroyo Quemado", "Carpenteria", "Mohawk", "Isla Vista",  "Naples")))
    
```

Create new `df` named `spiny_counts`

**d.** Create a new variable `counts` to allow for an analysis of lobster counts where the unit-level of observation is the total number of observed lobsters per `site`, `year` and `transect`.

-   Create a variable `mean_size` from the variable `size_mm`
-   NOTE: The variable `counts` should have values which are integers (whole numbers).
-   Make sure to account for missing cases (`na`)!

**e.** Create a new variable `mpa` with levels `MPA` and `non_MPA`. For our regression analysis create a numerical variable `treat` where MPA sites are coded `1` and non_MPA sites are coded `0`

```{r}
#HINT(d): Use `group_by()` & `summarize()` to provide the total number of lobsters observed at each site-year-transect row-observation. 
spiny_counts <- tidydata |> 
    group_by(site, year, transect) |> 
    summarise(counts = sum(count, na.rm = TRUE), mean_size_mm = mean(size_mm, na.rm = TRUE))

#HINT(e): Use `case_when()` to create the 3 new variable columns
spiny_counts <- spiny_counts |> 
    mutate(mpa = case_when(
        site %in% c("IVEE", "NAPL") ~ "MPA",
        site %in% c("MOHK", "CARP", "AQUE") ~ "non_MPA"),
        treat = case_when(
            mpa == "MPA" ~ 1,
            mpa == "non_MPA" ~ 0
        ))

```

> NOTE: This step is crucial to the analysis. Check with a friend or come to TA/instructor office hours to make sure the counts are coded correctly!

------------------------------------------------------------------------

#### Step 3: Explore & visualize data

**a.** Take a look at the data! Get familiar with the data in each `df` format (`tidydata`, `spiny_counts`)

**b.** We will focus on the variables `count`, `year`, `site`, and `treat`(`mpa`) to model lobster abundance. Create the following 4 plots using a different method each time from the 6 options provided. Add a layer (`geom`) to each of the plots including informative descriptive statistics (you choose; e.g., mean, median, SD, quartiles, range). Make sure each plot dimension is clearly labeled (e.g., axes, groups).

-   [Density plot](https://r-charts.com/distribution/density-plot-group-ggplot2)
-   [Ridge plot](https://r-charts.com/distribution/ggridges/)
-   [Jitter plot](https://ggplot2.tidyverse.org/reference/geom_jitter.html)
-   [Violin plot](https://r-charts.com/distribution/violin-plot-group-ggplot2)
-   [Histogram](https://r-charts.com/distribution/histogram-density-ggplot2/)
-   [Beeswarm](https://r-charts.com/distribution/beeswarm/)

Create plots displaying the distribution of lobster **counts**:

1)  grouped by reef site\
2)  grouped by MPA status
3)  grouped by year

Create a plot of lobster **size** :

4)  You choose the grouping variable(s)!

```{r}
# Plot1: Lobster counts by site
ggplot(spiny_counts, aes(x = counts, y = site, fill = mpa)) +
    geom_violin(quantile.linetype = "solid") +
    scale_fill_manual(values = c("MPA" = "darkgreen", "non_MPA" = "grey59")) +
    labs(x = "Lobster Count", y = "Site", fill = "MPA Status") +
    theme_classic()
```

```{r}
# Plot2: Lobster counts by mpa
spiny_counts <- spiny_counts |> 
    mutate(mpa = factor(mpa, levels = c("non_MPA", "MPA")))
means <- spiny_counts |> 
    group_by(mpa) |> 
    summarise(mean = mean(counts, na.rm = TRUE))
ggplot(spiny_counts, aes(x = counts, y = mpa)) +
    geom_density_ridges2(scale = 2) +

    geom_text(data = means, aes(x = mean + 30, y = as.numeric(mpa) + 0.7), label = "Mean count") +

    geom_segment(data = means, aes(x = mean, xend = mean, 
    y = as.numeric(mpa), yend = as.numeric(mpa) + 1), color = "red", 
    linewidth = 1, linetype = "dashed") +

    labs(x = "Lobster Count", y = "MPA Status") +

    theme_classic() +
    theme(legend.position = "none")
```

```{r}
# Plot3: Lobster count density by year
ggplot(spiny_counts, aes(x = counts, group = factor(year), color = factor(year))) +
    geom_density() +

    labs(x = "Lobster Counts", y = "Density", color = "Year") +

    theme_classic()
```

```{r}
# plot 4: Average lobster size by mpa
ggplot(spiny_counts, aes(x = mean_size_mm, fill = mpa)) +
    geom_histogram(alpha = 0.4, position = "identity") +
    scale_fill_manual(values = c("MPA" = "darkgreen", "non_MPA" = "grey59")) +

    labs(x = "Mean Lobster Size (mm)", y = "Count", fill = "MPA Status") +

    theme_classic()
```

**c.** Compare means of the outcome by treatment group. Using the `tbl_summary()` function from the package [`gt_summary`](https://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html)

```{r}
# USE: gt_summary::tbl_summary()
spiny_counts |> 
    tbl_summary(by = mpa, include = c(counts, mean_size_mm),
    statistic = list(all_continuous() ~ "{mean} ({sd})"))
```

------------------------------------------------------------------------

#### Step 4: OLS regression- building intuition

**a.** Start with a simple OLS estimator of lobster counts regressed on treatment. Use the function `summ()` from the [`jtools`](https://jtools.jacob-long.com/) package to print the OLS output

**b.** Interpret the intercept & predictor coefficients *in your own words*. Use full sentences and write your interpretation of the regression results to be as clear as possible to a non-academic audience.

```{r}
# NOTE: We will not evaluate/interpret model fit in this assignment (e.g., R-square)

m1_ols <- lm(counts ~ treat, data = spiny_counts)

summ(m1_ols, model.fit = FALSE) 

```

-   The intercept coefficient of 22.73 represents the y-intercept when `treat` = 0. This indicates an expected value of 22.73 lobsters in a non-MPA zone. The `treat` coefficient of 5.36 represents on average, MPA zones has counts of 5.36 more lobsters. However, the `treat` coefficient is non-significant, meaning there isn't sufficient evidence to say that MPAs have an effect on lobster counts.

**c.** Check the model assumptions using the `check_model` function from the `performance` package

**d.** Explain the results of the 4 diagnostic plots. Why are we getting this result?

```{r}
check_model(m1_ols,  check = "qq" )
```

The dots don't fall along the green line, indicating the residuals are not normally distributed. This is likely because we have count data which is often not normally distributed and a different model is needed.

```{r}
check_model(m1_ols, check = "normality")
```

Similarly, this test checks the normality of residuals. The distribution of residuals does not follow the normal curve because of the nature of our count data.

```{r}
check_model(m1_ols, check = "homogeneity")
```

The homogeneity plot does not follow a flat, horizontal shape. It is a U-like shape, indicating that the variance of residuals is not constant.

```{r}
check_model(m1_ols, check = "pp_check")
```

The posterior predictive check also does not match up. Since this predicts data from our data and compares to our observed data distributions. These lines differ greatly, meaning this model does not fit our data well.

------------------------------------------------------------------------

#### Step 5: Fitting GLMs

**a.** Estimate a Poisson regression model using the `glm()` function

**b.** Interpret the predictor coefficient in your own words. Use full sentences and write your interpretation of the results to be as clear as possible to a non-academic audience.

In this Poisson model, the predictor coefficient is 0.21. This value is reported in the log scale because of our log link function so undoing the log gives $e^{(0.21)} = 1.23$. Also because of this link function, the effects become multiplicative, so the expected count of the treatment group is 23% higher than the non-treatment.

**c.** Explain the statistical concept of dispersion and overdispersion in the context of this model.

In statistics, dispersion is the spread or variability of our data. In our example with overdispersion, there's too much variability in our lobster counts that Poisson can handle. In Poisson models, it is assumed that the variance = mean. Overdispersion means that our lobster counts' variance is actually greater than the mean and that a better model could be fit. 

**d.** Compare results with previous model, explain change in the significance of the treatment effect

Our new model's treatment effect indeed has a lower p-val and it is significant compared to the non-significant in the previous model. However, we must account for the overdispersion in this model as the Poisson does not include the large variability in our data. 

```{r}

m2_pois <- glm(counts ~ treat, data = spiny_counts, family = poisson(link = 'log'))

summ(m2_pois, model.fit = FALSE) 
```

**e.** Check the model assumptions. Explain results.

Poisson models assume:

- The probabilities of events are independent

- The rate of events is consistent

- The mean and variance are equal

In real-world count data, counts are not independent (counts are clustered/correlated), rate of events vary in time or space, and variance is often greater than the mean. 

**f.** Conduct tests for over-dispersion & zero-inflation. Explain results.

```{r}
check_model(m2_pois)
```

```{r}
check_overdispersion(m2_pois)
```

Overdispersion is detected, indicating variance > mean, a better model could be fit.

```{r}
check_zeroinflation(m2_pois)
```

Zero-inflation is probable, there are too many zeroes than the model can handle, a better model could be fit.

**g.** Fit a negative binomial model using the function glm.nb() from the package `MASS` and check model diagnostics

**h.** In 1-2 sentences explain rationale for fitting this GLM model.

Compared to the Poisson, a NB model adds another parameter that controls the variance so we don't have to assume variance = mean. 

**i.** Interpret the treatment estimate result in your own words. Compare with results from the previous model.

The same treatment coefficient resulted, 0.21, indicating a 23% increase in lobster counts in treatment zones.

```{r}
library(MASS) ## NOTE: The `select()` function is masked. Use: `dplyr::select()` ##
```

```{r}
# NOTE: The `glm.nb()` function does not require a `family` argument

m3_nb <- glm.nb(counts ~ treat, data = spiny_counts)

summ(m3_nb)

```

```{r}
check_overdispersion(m3_nb)
```

```{r}
check_zeroinflation(m3_nb)
```

```{r}
check_predictions(m3_nb)
```

```{r}
check_model(m3_nb)
```

------------------------------------------------------------------------

#### Step 6: Compare models

**a.** Use the `export_summ()` function from the `jtools` package to look at the three regression models you fit side-by-side.

**c.** Write a short paragraph comparing the results. Is the treatment effect `robust` or stable across the model specifications.

```{r}

export_summs(m1_ols, m2_pois, m3_nb,
             model.names = c("OLS","Poisson", "NB"),
             statistics = "none")

```

The treatment effect is not stable across our three models. While the estimated effect was somewhat consistent of two models estimating a 23% increase, statistical significance varied greatly. OLS and NB models had a non-significant treatment effect and Poisson had a highly significant effect. This appears to be a false positive of significance from the Poisson due to overdispersion in count data.

------------------------------------------------------------------------

#### Step 7: Building intuition - fixed effects

**a.** Create new `df` with the `year` variable converted to a factor

**b.** Run the following negative binomial model using `glm.nb()`

-   Add fixed effects for `year` (i.e., dummy coefficients)
-   Include an interaction term between variables `treat` & `year` (`treat*year`)

**c.** Take a look at the regression output. Each coefficient provides a comparison or the difference in means for a specific sub-group in the data. Informally, describe the what the model has estimated at a conceptual level (NOTE: you do not have to interpret coefficients individually)

This model also uses a log link like the Poisson, so each coefficient represents multiplicative effects of lobster counts. In this model we also included another predictor, year, which the coefficients represent how counts changed over time. We also have interaction terms between treat and year. This is the additional treatment effect that changes across each year, without it we'd be assuming that the treatment effect would be constant every year.

**d.** Explain why the main effect for treatment is negative? \*Does this result make sense?

The treatment coefficient represents how treatment changes our counts in 2012, the negative value indicates that treatment sites had lower counts initially. Interpreting the treatment coefficient in the non-link, treatment sites had a 82% reduction in counts. However, this changes over time past 2012 and treatment counts increased indicated by the positive interaction coefficients.

```{r}

ff_counts <- spiny_counts %>% 
    mutate(year=as_factor(year))
    
m5_fixedeffs <- glm.nb(
    counts ~ treat + year + treat*year,
    data = ff_counts)

summ(m5_fixedeffs, model.fit = FALSE)
```

**e.** Look at the model predictions: Use the `interact_plot()` function from package `interactions` to plot mean predictions by year and treatment status.

**f.** Re-evaluate your responses (c) and (b) above.

```{r}

interact_plot(m5_fixedeffs, pred = year, modx = treat,
              outcome.scale = "link") # NOTE: y-axis on log-scale

# HINT: Change `outcome.scale` to "response" to convert y-axis scale to counts
interact_plot(m5_fixedeffs, pred = year, modx = treat,
              outcome.scale = "response")
```

**g.** Using `ggplot()` create a plot in same style as the previous `interaction plot`, but displaying the original scale of the outcome variable (lobster counts). This type of plot is commonly used to show how the treatment effect changes across discrete time points (i.e., panel data).

The plot should have... - `year` on the x-axis - `counts` on the y-axis - `mpa` as the grouping variable

```{r}
# Hint 1: Group counts by `year` and `mpa` and calculate the `mean_count`
# Hint 2: Convert variable `year` to a factor

plot_counts <- ff_counts |> 
    group_by(year, mpa) |> 
    summarise(mean_count = mean(counts, na.rm = TRUE))

plot_counts |> ggplot(aes(year, mean_count, color = mpa, group = mpa)) +
    geom_point() +
    geom_line() +
    theme_classic()
```

------------------------------------------------------------------------

#### Step 8: Reconsider causal identification assumptions

a.  Discuss whether you think `spillover effects` are likely in this research context (see Glossary of terms; https://docs.google.com/document/d/1RIudsVcYhWGpqC-Uftk9UTz3PIq6stVyEpT44EPNgpE/edit?usp=sharing)

Spillover effects are possible, treatment groups could cause increased counts to spillover into nearby sites as lobsters to walk over to nonmpa sites due to migration or other environmental/behavioral reasons.

b.  Explain why spillover is an issue for the identification of causal effects

This is an issue because the control group would also start seeing benefits by the treatment. This defeats the purpose of the control. The outcome of the treatment should not affect the outcome of the control. This makes it more difficult to measure a causal effect.

c.  How does spillover relate to impact in this research setting?

If spillover occurs between treatment groups, the causal effect could become obscure to researchers, inhibiting the evaluation of MPAs on lobster counts and size.

d.  Discuss the following causal inference assumptions in the context of the MPA treatment effect estimator. Evaluate if each of the assumption are reasonable:

    1)  SUTVA: Stable Unit Treatment Value assumption

    The assumptions states that there should be no interference between groups and that all treatment groups receive the same treatment. As stated before spillover is possible in these sites, this first assumption is violated. The second is not however, as all MPAs are under the same regulations.

    2)  Excludability assumption

    The assumption states that only mpa status contributes to the outcome of lobster counts. This is somewhat hard to measure and account for all possible confounders, but for this lter study, seems reasonable.

------------------------------------------------------------------------

# EXTRA CREDIT

> Use the recent lobster abundance data with observations collected up until 2024 (`extracredit_sblobstrs24.csv`) to run an analysis evaluating the effect of MPA status on lobster counts using the same focal variables.

a.  Create a new script for the analysis on the updated data
b.  Run at least 3 regression models & assess model diagnostics
c.  Compare and contrast results with the analysis from the 2012-2018 data sample (\~ 2 paragraphs)

------------------------------------------------------------------------

![](figures/spiny1.png)